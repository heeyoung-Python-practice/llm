{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7275513d",
   "metadata": {},
   "source": [
    "# LCEL(LangChain Expression Language)\n",
    "https://reference.langchain.com/python/langchain_core/runnables/\n",
    "\n",
    "https://reference.langchain.com/python/langchain_core/runnables/?h=runnablelambd#langchain_core.runnables.base.RunnableLambda\n",
    "  \n",
    "- LCEL(LangChain Expression Language)ì€ LangChainì—ì„œ ì²´ì¸ì„ ì„ ì–¸ì ìœ¼ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë„ë©”ì¸ íŠ¹í™” ì–¸ì–´ë‹¤.  \n",
    "- `|` ì—°ì‚°ìë¥¼ ì‚¬ìš©í•´ í”„ë¡¬í”„íŠ¸, ëª¨ë¸, íŒŒì„œ ë“±ì„ íŒŒì´í”„ë¼ì¸ì²˜ëŸ¼ ì—°ê²°í•œë‹¤.\n",
    "\n",
    "**ì£¼ìš” íŠ¹ì§•**\n",
    "\n",
    "- **ì„ ì–¸ì  ë¬¸ë²•**: Unix íŒŒì´í”„ì²˜ëŸ¼ `chain = prompt | model | parser` í˜•íƒœë¡œ ì§ê´€ì ì´ë‹¤.  \n",
    "- **ëª¨ë“ˆì„±Â·ìœ ì—°ì„±**: í”„ë¡¬í”„íŠ¸, LLM, íŒŒì„œ, ê²€ìƒ‰ê¸°, ë©”ëª¨ë¦¬ ë“± ì»´í¬ë„ŒíŠ¸ë¥¼ ììœ ë¡­ê²Œ ì¡°í•©í•  ìˆ˜ ìˆë‹¤.  \n",
    "- **ë™ê¸°/ë¹„ë™ê¸° ì§€ì›**: ë‹¨ì¼ ì½”ë“œë¡œ ë™ê¸°ì‹Â·ë¹„ë™ê¸°ì‹ ì‹¤í–‰ì„ ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.  \n",
    "- **ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”**: ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„ëŠ” ìë™ìœ¼ë¡œ ë³‘ë ¬í™”í•´ ì§€ì—° ì‹œê°„ì„ ì¤„ì¸ë‹¤.  \n",
    "- **ê³ ê¸‰ ê¸°ëŠ¥ ê¸°ë³¸ ì œê³µ**:  \n",
    "  - ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ìœ¼ë¡œ ì‘ë‹µ ì†ë„ë¥¼ í–¥ìƒì‹œí‚¨ë‹¤.  \n",
    "  - ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ì™€ í´ë°± ê²½ë¡œë¥¼ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.  \n",
    "  - ì¤‘ê°„ ê²°ê³¼ì— ì ‘ê·¼í•´ ë””ë²„ê¹…ì´ë‚˜ ì§„í–‰ ìƒí™© í‘œì‹œê°€ ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "**LCELì˜ ì£¼ìš” ê¸°ëŠ¥**\n",
    "\n",
    "1. **ìŠ¤íŠ¸ë¦¬ë° ì§€ì›**: ì²« í† í° ë„ë‹¬ ì‹œê°„ì„ ë‹¨ì¶•í•´ ì‹¤ì‹œê°„ì„±ì„ ë†’ì¸ë‹¤.  \n",
    "2. **ë¹„ë™ê¸° ì§€ì›**: asyncio í™˜ê²½ ë“± ë‹¤ì–‘í•œ ì‹¤í–‰ í™˜ê²½ì„ ë™ì¼ ì½”ë“œë¡œ ì§€ì›í•œë‹¤.  \n",
    "3. **ë³‘ë ¬ ì‹¤í–‰ ìµœì í™”**: ë³‘ë ¬í™” ê°€ëŠ¥í•œ ë‹¨ê³„ëŠ” ìë™ìœ¼ë¡œ ë¶„ë¦¬í•´ ë™ì‹œì— ì‹¤í–‰í•œë‹¤.  \n",
    "4. **ì¬ì‹œë„Â·í´ë°± êµ¬ì„±**: ì˜¤ë¥˜ ë°œìƒ ì‹œ ì§€ì • íšŸìˆ˜ë§Œí¼ ì¬ì‹œë„í•˜ê±°ë‚˜ ëŒ€ì²´ ê²½ë¡œë¥¼ ì‹¤í–‰í•œë‹¤.  \n",
    "5. **ì¤‘ê°„ ê²°ê³¼ ì ‘ê·¼**: ìµœì¢… ì¶œë ¥ ì´ì „ì— ê° ë‹¨ê³„ì˜ ì¶œë ¥ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "**ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ**\n",
    "\n",
    "- **Runnable**: LCELì˜ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ìƒì†í•˜ëŠ” ê¸°ë³¸ í´ë˜ìŠ¤ë‹¤.  \n",
    "- **Chain**: ì—¬ëŸ¬ Runnableì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•œë‹¤.  \n",
    "- **RunnableMap**: ì—¬ëŸ¬ Runnableì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•œë‹¤.  \n",
    "- **RunnableSequence**: Runnableë“¤ì˜ ì‹œí€€ìŠ¤ë¥¼ ì •ì˜í•œë‹¤.  \n",
    "- **RunnableLambda**: íŒŒì´ì¬ í•¨ìˆ˜ë¥¼ ë˜í•‘í•´ Runnableë¡œ ë§Œë“ ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8293589d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openapi -Uqqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  # .env íŒŒì¼ì˜ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "import os                       # í™˜ê²½ë³€ìˆ˜ ì ‘ê·¼ìš©\n",
    "\n",
    "load_dotenv()                   # í˜„ì¬ ìœ„ì¹˜ì˜ .envë¥¼ ì½ì–´ì™€ í™˜ê²½ë³€ìˆ˜ë¡œ ë“±ë¡\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"openai_key\")  # .envì˜ openai_key ê°’ì„ OPENAI_API_KEYë¡œ ë“±ë¡\n",
    "os.environ[\"LANGSMITH_TRACING\"] = 'true'                # LangSmith íŠ¸ë ˆì´ì‹± í™œì„±í™”\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = 'https://eu.api.smith.langchain.com'  # LangSmith API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = 'skn23-langchain'                   # LangSmith í”„ë¡œì íŠ¸ëª… ì„¤ì •\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"langsmith_key\")          # .envì˜ langsmith_key ê°’ì„ LANGSMITH_API_KEYë¡œ ë“±ë¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e73c0",
   "metadata": {},
   "source": [
    "## RunnableLambda\n",
    "ì¼ë°˜ python í•¨ìˆ˜ë¥¼ lcel ì²´ì¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ wrapping ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41dc39f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda # ì…ë ¥ì„ ë°›ì•„ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ëŠ” Runnable\n",
    "\n",
    "runnable = RunnableLambda(lambda x:len(x))          # ì…ë ¥ xì˜ ê¸¸ì´ë¥¼ ë°˜í™˜í•˜ëŠ” Runnable ìƒì„±\n",
    "runnable.invoke('í”Œë ˆì´ë°ì´í„° ë…ì‚° skn-23 í™”ì´íŒ…!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6684835f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 2, 6, 4]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch : ì—¬ëŸ¬ ê±´ì˜ ì…ë ¥ì„ ì¼ê´„ì²˜ë¦¬í•˜ëŠ” ë©”ì†Œë“œ\n",
    "runnable.batch(['í”Œë ˆì´ë°ì´í„°','ë…ì‚°','skn-23','í™”ì´íŒ…!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "963d72fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32.0, 77.0, 212.0, 14.0, 98.6]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì„­ì”¨ ì…ë ¥ê°’ì„ í™”ì”¨ë¡œ ë³€í™˜í•˜ëŠ” runnable ìƒì„±\n",
    "\n",
    "def calsius_to_fahrenheit(calsius):\n",
    "    \"\"\"ì„­ì”¨ ì˜¨ë„ë¥¼ í™”ì”¨ ì˜¨ë„ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    return calsius *9/5+32\n",
    "\n",
    "celsius_temps = [0,25,100,-10,37]\n",
    "runnable = RunnableLambda(calsius_to_fahrenheit)\n",
    "runnable.batch(celsius_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a73681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~ ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~ ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~ ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~ ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~ ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~"
     ]
    }
   ],
   "source": [
    "# streamìœ¼ë¡œ ì œë„ˆë í„° ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë°í•˜ê¸°\n",
    "import time # ì¶œë ¥ ë”œë ˆì´ìš©\n",
    "\n",
    "def gen(x):\n",
    "    \"\"\"ì…ë ¥ ë¬¸ìì—´ì„ í•œ ê¸€ì(ë¬¸ì)ì”© yieldí•˜ëŠ” ì œë„ˆë ˆì´í„°\"\"\"\n",
    "    for y in x: # ì„ë ¥ì„ ìˆœíšŒ(ë¬¸ì ë‹¨ìœ„)\n",
    "        yield y # í•œ ê¸€ìì”© ë°˜í™˜(ìŠ¤íŠ¸ë¦¬ë° ë‹¨ìœ„)\n",
    "\n",
    "runnable = RunnableLambda(gen)  # ë¬¸ìì—´ ì œë„ˆë ˆì´í„° í•¨ìˆ˜ë¥¼ Runnableë¡œ ë˜í•‘\n",
    "for chunk in runnable.stream(\"ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~ ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~ ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~ ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~ ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~ ì•ˆë…•í•˜ì„¸ìš”? ì•ˆë…•í•˜ì„¸ìš”! ì•ˆë…•í•˜ì„¸ìš”~\"):\n",
    "    print(chunk,end=\"\",flush=True)  # chunkë¥¼ ì¤„ë°”ê¿ˆ ì—†ì´ ì¦‰ì‹œ ì¶œë ¥\n",
    "    time.sleep(0.1)                 # 0.1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì²œì²œíˆ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d28f974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object gen at 0x000002822A876980>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen(x):\n",
    "    \"\"\"iterableì„ ë°›ì•„ ì›ì†Œë¥¼ í•˜ë‚˜ì”© yieldí•˜ëŠ” ì œë„ˆë ˆì´í„°\"\"\"\n",
    "    for y in x: # ì„ë ¥ì„ ìˆœíšŒ(ë¬¸ì ë‹¨ìœ„)\n",
    "        yield y # í•œ ê¸€ìì”© ë°˜í™˜(ìŠ¤íŠ¸ë¦¬ë° ë‹¨ìœ„)\n",
    "        \n",
    "gen10 = gen(range(10))  # 0~9ë¥¼ í•˜ë‚˜ì”© êº¼ë‚´ëŠ” ì œë„ˆë ˆì´í„° ìƒì„±\n",
    "gen10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc11f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for n in gen10: # gen10ì—ì„œ ê°’ì„ í•˜ë‚˜ì”© êº¼ë‚´ë©° ìˆœíšŒ (êº¼ë‚¸ ê°’ì€ ë‹¤ì‹œ ì‚¬ìš©ëª»í•¨)\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce81945",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen10 = gen(range(10))  # 0~9ë¥¼ í•˜ë‚˜ì”© êº¼ë‚´ëŠ” ì œë„ˆë ˆì´í„° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cb7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen10) # ì œë„ˆë ˆì´í„°ì—ì„œ ë‹¤ìŒ ê°’ì„ 1ê°œ ë°˜í™˜(ë‹¤ êº¼ë‚´ë©´ StopIteration ë°œìƒ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1be6a",
   "metadata": {},
   "source": [
    "## RunnablleSequenc\n",
    "Runnablleê°ì²´ë¥¼ ìˆœì°¨ì—°ê²°í•˜ëŠ” Runnable ê°ì²´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f24e5932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'foo': 3}, {'foo': 3}, {'foo': 3}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence   # Runnableë“¤ì„ ìˆœì„œëŒ€ë¡œ ì—°ê²°í•˜ëŠ” ì‹œí€€ìŠ¤\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {'foo':x})\n",
    "runnable2 = RunnableLambda(lambda x: [x] * 3)\n",
    "\n",
    "chain = RunnableSequence(runnable1, runnable2)\n",
    "# chain = runnable1 | runnable2\n",
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a26f0",
   "metadata": {},
   "source": [
    "## RunnableParellel\n",
    "ì—¬ëŸ¬ Runnableê°ì²´ë¥¼ ì¸ìë¡œ ë°›ì•„, ë³‘ëŸ´ ì²˜ë¦¬ í›„ ê°ê°ì˜ ì‘ë‹µì„ í•˜ë‚˜ì˜ dict í˜•íƒœë¡œ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "120e026a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r1': {'foo': 3}, 'r2': [3, 3, 3]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel   # ì—¬ëŸ¬ Runnableë“¤ì„ ê°™ì€ ì…ë ¥ìœ¼ë¡œ ë³‘ë ¬ ì‹¤í–‰\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {'foo':x})\n",
    "runnable2 = RunnableLambda(lambda x: [x] * 3)\n",
    "\n",
    "chain = RunnableParallel(r1=runnable1, r2=runnable2)\n",
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc034a41",
   "metadata": {},
   "source": [
    "ì‚¬ìš©ìê°€ ì§€ì •í•œ ì£¼ì œ(Topic)ì— ëŒ€í•´ì„œ ì‚¼í–‰ì‹œ, ë†ë‹´,ì‹œë¥¼ ê°€ê° ìƒì„±í•´ì„œ í•˜ë‚˜ì˜ ì‘ë‹µì„ ì‘ì„±í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48c6c6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ní–‰ì‹œ : \n",
      "ì•„: ì•„ë¦„ë‹¤ìš´ ì—¬ë¦„ ë‚ ,  \n",
      "ì´: ì´ í•œ ì…ì— ì‹œì›í•¨ì´ ê°€ë“í•´ìš”.  \n",
      "ìŠ¤: ìŠ¤ë¥´ë¥´ ë…¹ì•„ë“œëŠ” ë‹¬ì½¤í•¨,  \n",
      "í¬: í¬ë¦¼ì²˜ëŸ¼ ë¶€ë“œëŸ¬ìš´ ê·¸ ë§›,  \n",
      "ë¦¼: ë¦¼ ì—†ì´ í–‰ë³µí•œ ìˆœê°„ì„ ì„ ì‚¬í•´ìš”.\n",
      "\n",
      "ë†ë‹´ :\n",
      "ì•„ì´ìŠ¤í¬ë¦¼ì´ë‘ ëŒ€í™”í–ˆë”ë‹ˆ ì´ë ‡ê²Œ í•˜ë”ë¼ê³ ìš”.\n",
      "\n",
      "\"ë„ˆ ë‚´ ë§ì— ë„ˆë¬´ ë…¹ì•„ë‚´ë¦¬ì§€ ë§ˆ!\" ğŸ˜„ğŸ¦\n",
      "\n",
      "ì‹œ:\n",
      "ì—¬ë¦„ë‚  í–‡ì‚´ ì†,  \n",
      "ì†ëì— ë…¹ì•„ë“œëŠ” ê·¸ëŒ€,  \n",
      "ë‹¬ì½¤í•œ ê¸°ì–µ í•œ ìŠ¤í‘¼,  \n",
      "ì•„ì´ìŠ¤í¬ë¦¼ í•œ ì… ì†ì— ìˆ¨ê²¨ì§„ ê¿ˆ.\n",
      "\n",
      "ë°”ì‚­í•œ ì™€í”Œ ì½˜ ì•ˆì—  \n",
      "ì°¨ê°€ìš´ ì†ì‚­ì„ì´ ë§´ëŒê³ ,  \n",
      "í•œ ìˆœê°„ì˜ ì‹œì›í•¨ ë’¤ì—  \n",
      "í•ì¤„ì²˜ëŸ¼ íë¥´ëŠ” ë”°ìŠ¤í•¨.\n",
      "\n",
      "í˜€ëì— ë²ˆì§€ëŠ” ìƒ‰ìƒ‰ì˜ ë¹›ê¹”ì€  \n",
      "ì–´ë¦° ì‹œì ˆì˜ ì›ƒìŒê³¼ ë…¸ë˜,  \n",
      "ì‚¬ë‘ì˜ ë§›ì„ ë‹®ì€ ê·¸ë¦¬ì›€,  \n",
      "ë…¹ì•„ë‚´ë¦¬ëŠ” ì‹œê°„ ì†ì— ê¹ƒë“  ì†Œì¤‘í•¨.\n",
      "\n",
      "ì•„ì´ìŠ¤í¬ë¦¼, ë„ˆëŠ”  \n",
      "ëœ¨ê±°ìš´ ë§ˆìŒì„ ì‹íˆëŠ” ì†ê¸¸,  \n",
      "ì„¸ìƒ ëª¨ë“  ì—¬ë¦„ì˜ ê¸°ì–µì„  \n",
      "í•œ ìŠ¤í‘¼ì— ë‹´ì•„ ë‚´ëŠ” ë§ˆë²•.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "\n",
    "llm = init_chat_model(model='gpt-4.1-mini')\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "acrostic_poem_prompt = PromptTemplate.from_template(\n",
    "    'ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ní–‰ì‹œ ê³ ìˆ˜ì…ë‹ˆë‹¤. ë‹¤ìŒ ì£¼ì œë¡œ ní–‰ì‹œë¥¼ ì§€ì–´ì£¼ì„¸ìš”.\\n\\nì£¼ì œ:{topic}'\n",
    ")\n",
    "acrostic_poem_chain = acrostic_poem_prompt | llm | output_parser\n",
    "\n",
    "joke_prompt = PromptTemplate.from_template(\n",
    "    'ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ë†ë‹´ ê³ ìˆ˜ì…ë‹ˆë‹¤. ë‹¤ìŒ ì£¼ì œë¡œ í—ˆë¥¼ ì°Œë¥´ëŠ” ë†ë‹´ì„ í•˜ë‚˜ í•´ì£¼ì„¸ìš”.\\n\\nì£¼ì œ:{topic}'\n",
    ")\n",
    "joke_chain = joke_prompt | llm | output_parser\n",
    "\n",
    "poem_prompt = PromptTemplate.from_template(\n",
    "    'ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì‹œì¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ì£¼ì œë¡œ ê°ì„±ì ì¸ ì‹œë¥¼ ì§€ì–´ì£¼ì„¸ìš”.\\n\\nì£¼ì œ:{topic}'\n",
    ")\n",
    "poem_chain = poem_prompt | llm | output_parser\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    acrostic_poem = acrostic_poem_chain,\n",
    "    joke = joke_chain,\n",
    "    poem = poem_chain\n",
    ")\n",
    "\n",
    "def combine_result(input_dict: dict) -> str:\n",
    "    \"\"\"ë³‘ë ¬ ê²°ê³¼(ní–‰ì‹œ/ë†ë‹´/ì‹œ)ë¥¼ í•œ ë¬¸ìì—´ë¡œ í•©ì³ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    acrostic_poem = input_dict['acrostic_poem']\n",
    "    joke = input_dict['joke']\n",
    "    poem = input_dict['poem']\n",
    "    return f\"\"\"\n",
    "ní–‰ì‹œ : \n",
    "{acrostic_poem}\n",
    "\n",
    "ë†ë‹´ :\n",
    "{joke}\n",
    "\n",
    "ì‹œ:\n",
    "{poem}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chain = chain | RunnableLambda(combine_result)\n",
    "print(chain.invoke({'topic':'ì•„ì´ìŠ¤í¬ë¦¼'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac7d78",
   "metadata": {},
   "source": [
    "\n",
    "## RunnablePassThought\n",
    "- ì‚¬ìš©ìì˜ ì…ë ¥ê°’ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬\n",
    "- ì…ë ¥ dictë¥¼ í™•ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f54cc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'í…€: í…€ì„ ë‘ê³  ë§ˆì‹œëŠ” ë”°ëœ»í•œ ì°¨ í•œ ì”  \\në¸”: ë¸”ë§ë¸”ë§ ë¹›ë‚˜ëŠ” ë‚˜ë§Œì˜ ë³´ì˜¨ë³‘  \\nëŸ¬: ëŸ¬ë‹í•˜ë“¯ ë°”ë¹ ë„ í•¨ê»˜í•˜ëŠ” ì¹œêµ¬ì²˜ëŸ¼'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = init_chat_model(model='openai:gpt-4.1-mini')\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    'ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ní–‰ì‹œ ê³ ìˆ˜ì…ë‹ˆë‹¤. ë‹¤ìŒ ì£¼ì œë¡œ ní–‰ì‹œë¥¼ ì§€ì–´ì£¼ì„¸ìš”.\\n\\nì£¼ì œ:{topic}'\n",
    ")\n",
    "\n",
    "chain = ({'topic': RunnablePassthrough()}   # ì…ë ¥(ë¬¸ìì—´)ì„ ê·¸ëŒ€ë¡œ ë°›ì•„ {'topic':ì…ë ¥}ìœ¼ë¡œ ë§¤í•‘\n",
    "         | prompt \n",
    "         | llm \n",
    "         | output_parser\n",
    ")\n",
    "\n",
    "chain.invoke('í…€ë¸”ëŸ¬')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61d59bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'===== í•™ì› 2í–‰ì‹œ =====  \\ní•™: í•™ìƒë“¤ ê¿ˆ í‚¤ìš°ëŠ” ê³³,  \\nì›: ì›ëŒ€í•œ ë¯¸ë˜ì˜ ì¶œë°œì .'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough    # ì…ë¥´ê²¨ì„ ê·¸ëŒ€ë¡œ í†µê³¼ì‹œí‚¤ëŠ” Runnable\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ {n}í–‰ì‹œ ê³ ìˆ˜ì…ë‹ˆë‹¤. ë‹¤ìŒ ì£¼ì œë¡œ {n}í–‰ì‹œë¥¼ ì§€ì–´ì£¼ì„¸ìš”\n",
    "    \n",
    "# ì£¼ì œ:\n",
    "{topic}\n",
    "\n",
    "# ì¶œë ¥ í˜•ì‹:\n",
    "===== <ì£¼ì œ> <n>í–‰ì‹œ =====\n",
    "<ní–‰ì‹œ ì‘ì„±>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {'topic': RunnablePassthrough()}\n",
    "     | RunnablePassthrough.assign(\n",
    "         n=lambda x: len(x['topic'])\n",
    "     )\n",
    "     | prompt\n",
    "     | llm\n",
    "     | output_parser\n",
    ")\n",
    "\n",
    "chain.invoke('í•™ì›')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708602a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

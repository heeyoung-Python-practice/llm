{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074c7193",
   "metadata": {},
   "source": [
    "# Model I/O\n",
    "\n",
    "![](https://d.pr/i/Wy5B5B+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7849e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community langchain-openai langchain-huggingface python-dotenv -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0a07e",
   "metadata": {},
   "source": [
    "-q : 진행 로그 일부 숨김  \n",
    "-qq : 대부분 숨김  \n",
    "-qqq : 성공 메시지까지 거의 다 숨김(문제가 생길경우만 로그 본다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac45832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  # .env 파일의 환경변수 로드\n",
    "import os                       # 환경변수 접근용\n",
    "\n",
    "load_dotenv()                   # 현재 위치의 .env를 읽어와 환경변수로 등록\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"openai_key\")  # .env의 openai_key 값을 OPENAI_API_KEY로 등록\n",
    "os.environ[\"LANGSMITH_TRACING\"] = 'true'                # LangSmith 트레이싱 활성화\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = 'https://eu.api.smith.langchain.com'  # LangSmith API 엔드포인트 설정\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = 'skn23-langchain'                   # LangSmith 프로젝트명 설정\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"langsmith_key\")          # .env의 langsmith_key 값을 LANGSMITH_API_KEY로 등록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d510b2aa",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb745af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'물론이죠! 핀란드는 자연과 문화가 조화를 이루는 아름다운 나라로, 다양한 매력을 가진 여행지가 많아요. 몇 가지 추천해드릴게요.\\n\\n1. **헬싱키 (Helsinki)**  \\n   - 핀란드의 수도로서 현대적인 도시 분위기와 역사적인 건축물이 공존하는 곳입니다.  \\n   - 신설 청사, 템펠리아우키오 교회(암석교회), 수오멘린나 요새 등을 방문해보세요.  \\n   - 디자인 디스트릭트에서 핀란드 특유의 디자인과 아트를 즐길 수 있어요.\\n\\n2. **로바니에미 (Rovaniemi)**  \\n   - 북극권에 위치한 도시로, 산타클로스 마을이 유명합니다.  \\n   - 겨울철에는 오로라(북극광)를 볼 수 있는 최적의 장소 중 하나입니다.  \\n   - 순록 썰매, 개썰매 체험 등 겨울 액티비티도 다양해요.\\n\\n3. **사리셀카 (Saariselkä)**  \\n   - 라플란드 지역의 인기 스키 리조트로, 자연 그대로의 아름다운 풍경과 함께 다양한 야외 활동을 즐길 수 있습니다.  \\n   - 여름에는 하이킹과 산악 자전거, 겨울에는 스키와 눈신발 걷기가 인기입니다.\\n\\n4. **탐페레 (Tampere)**  \\n   - 핀란드 제3의 도시로 산업도시였지만 현재는 문화와 예술의 중심지입니다.  \\n   - 많은 박물관과 극장이 있으며, 시내에는 아름다운 호수들이 많아요.  \\n   - 유명한 사우나 문화를 체험하는 것도 추천합니다.\\n\\n5. **사보누르시 (Savonlinna)**  \\n   - 올란타호(호수 위의 올란드 요새)의 중세 성인 올란다성(Olavinlinna)으로 유명합니다.  \\n   - 여름에 열리는 오페라 축제도 세계적으로 유명합니다.\\n\\n6. **쿠오피오 (Kuopio)**  \\n   - 핀란드 동부에 위치한 도시로, 아름다운 호수와 자연 경관이 인상적입니다.  \\n   - 푸헬리 호수(Saana Lake) 주변의 전망대에서 멋진 경치를 볼 수 있어요.\\n\\n핀란드는 사계절 모두 매력이 다르기 때문에, 여행하시는 계절에 따라 방문지를 선택하는 것도 좋습니다! 추가로 여행 스타일이나 관심사 알려주시면 더 맞춤 추천도 가능합니다.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init_chat_model : 추상화된 llm모델 객체 생성\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# OpenAI 모델 지정 + 파라미터 설정\n",
    "# llm = init_chat_model(model='gpt-4.1-mini', model_provider='openai', temperature=1, top_p=1)\n",
    "llm = init_chat_model(model='gpt-4.1-mini', temperature=1, top_p=1)\n",
    "ai_message = llm.invoke(\"핀란드의 여행지 추천해줘.\")    # 프롬프트 호출 -> AIMessage 반환\n",
    "ai_message.content  # 보문 텍스트만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb44f2a",
   "metadata": {},
   "source": [
    "- 추상화된 채팅 LLM: init_chat_model()이 특정회사(OpeaAI / Anthropic / HuggingFace)의 클래스에 직접 묶이지 않게,\n",
    "공통 인터페이스로 같은 방식(invoke, stream 등)으로 쓰게 만들어준다.  \n",
    "즉, init_chat_model()은 OpenAI 객체를 만드는 방식이 아니라, 여러 채팅 LLM들을 공통규격으로 감싸서(추상화해서) 동일하게 쓸 수 있도록 만들어주는 팩토리 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d138c",
   "metadata": {},
   "source": [
    "### HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1cf0e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nTranslate this to French. I love programming~<|im_end|>\\n<|im_start|>assistant\\nJ'aime le programmation~\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init_chat_model : 추상화된 llm모델 객체 생성\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# OpenAI 모델 지정 + 파라미터 설정\n",
    "llm = init_chat_model(model='huggingface:Qwen/Qwen2.5-0.5B-Instruct', temperature=1)\n",
    "ai_message = llm.invoke(\"Translate this to French. I love programming~\")    # 프롬프트 호출 -> AIMessage 반환\n",
    "ai_message.content  # 보문 텍스트만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd1a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== gpt-4.1-mini =====\n",
      "랭체인(LangChain)의 장점은 여러 가지가 있는데, 주로 대규모 언어 모델(LLM)과 다양한 데이터 소스, 애플리케이션을 효과적으로 연결하고 활용할 수 있게 돕는다는 점에 있습니다. 주요 장점들을 정리해 드리면 다음과 같습니다:\n",
      "\n",
      "1. **모듈화 및 확장성**  \n",
      "   랭체인은 체인(chain), 프롬프트, 메모리, 에이전트 등 여러 구성 요소를 모듈화하여 제공해 필요에 따라 유연하게 조합하고 확장할 수 있습니다.\n",
      "\n",
      "2. **다양한 데이터 소스 연동**  \n",
      "   문서, 데이터베이스, API, 웹사이트 등 다양한 외부 데이터 소스와 쉽게 통합할 수 있어, LLM을 단순한 생성 모델에서 벗어나 실제 응용 가능한 솔루션으로 확장할 수 있습니다.\n",
      "\n",
      "3. **복잡한 워크플로우 구현 지원**  \n",
      "   단순 질의응답을 넘어, 여러 단계의 작업을 순차적으로 처리하는 복합적인 워크플로우도 손쉽게 구현 가능합니다.\n",
      "\n",
      "4. **자동화 및 에이전트 기능**  \n",
      "   여러 도구(tool) 및 API 호출을 조합해 상황에 맞는 최적의 행동을 결정하는 에이전트 기능을 갖추고 있어, 자동화된 비즈니스 프로세스나 챗봇 등에 활용할 수 있습니다.\n",
      "\n",
      "5. **커뮤니티 및 생태계 활성화**  \n",
      "   오픈소스 기반이며, 활발한 커뮤니티가 존재해 지속적인 기능 개선과 플러그인, 예제 등이 풍부합니다.\n",
      "\n",
      "6. **언어 및 플랫폼 독립성**  \n",
      "   Python 중심이지만 다양한 언어 및 플랫폼에서 사용할 수 있는 SDK와 연동 가능성을 넓혀, 개발 편의성을 높였습니다.\n",
      "\n",
      "요약하면, 랭체인은 LLM을 실제 애플리케이션에 맞게 통합, 확장, 자동화할 수 있도록 지원하는 강력한 프레임워크로, 개발자가 빠르게 고도화된 AI 시스템을 구축할 수 있도록 돕는 도구입니다.\n",
      "\n",
      "===== Qwen/Qwen2.5-0.5B-Instruct =====\n",
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "랭체인의 장점이 뭐야?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "저는 AI 어시스턴트로서 정보를 제공하는 능력이 있으며, 개인적인 감정이나 가치관을 가지고 있지 않습니다. 저는 인공지능 대신 더 큰 범위에서 정보를 제공하고 도움을 줍니다. 어떤 질문에 대해 도와드릴까요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 서로 다른 provider 모델들을 리스트로 준비\n",
    "models = [\n",
    "    init_chat_model('openai:gpt-4.1-mini'),\n",
    "    init_chat_model('huggingface:Qwen/Qwen2.5-0.5B-Instruct')\n",
    "]\n",
    "\n",
    "user_prompt = '랭체인의 장점이 뭐야?'\n",
    "\n",
    "for model in models:\n",
    "    # model 객체에 model_name 속성이 있으면 model_name, 없으면 model_id를 사용\n",
    "    model_name = model.model_name if hasattr(model, 'model_name') else model.model_id\n",
    "    print(f\"===== {model_name} =====\")\n",
    "    ai_message=model.invoke(user_prompt)\n",
    "    print(ai_message.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c30ea5",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4880b0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'랭체인(LangChain)과 랭그래프(LangGraph)는 주로 자연어 처리 및 인공지능 언어 모델과 관련된 도구 및 개념입니다.\\n\\n1. 랭체인(LangChain):\\n- 랭체인은 언어 모델(Large Language Models, LLM)을 활용한 애플리케이션 개발을 쉽게 해주는 오픈소스 프레임워크입니다.\\n- 예를 들어, 여러 데이터 소스와 모델을 연결(chain)해 복잡한 작업을 자동화하거나, 대화형 AI, 문서 분석, 맞춤형 질의응답 시스템 구축에 도움을 줍니다.\\n- 텍스트 생성, 요약, 번역, 정보 추출 등 다양한 NLP 작업에 적용할 수 있으며, 파이썬 기반으로 개발자 친화적입니다.\\n\\n2. 랭그래프(LangGraph):\\n- 랭그래프는 LLM과 관련해 언어 모델의 출력과 작업 흐름을 그래프 형태로 시각화하거나 설계하는 개념이나 도구를 의미할 수 있습니다.\\n- 여러 작업 단계(노드)와 그 관계(엣지)를 그래프로 표현해 복잡한 언어 처리 파이프라인을 이해하고 관리하는 데 도움을 줍니다.\\n- 구체적인 구현이나 제품명은 다양할 수 있으나, 랭체인 내에서 또는 유사한 AI 도구에서 워크플로우 최적화, 디버깅 등에 활용됩니다.\\n\\n요약하자면, 랭체인은 언어 모델을 활용한 응용 프로그램 개발을 지원하는 프레임워크이고, 랭그래프는 그런 모델과 작업 흐름을 그래프로 관리·시각화하는 개념 또는 도구라고 생각하시면 됩니다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시스템/유저 메시지 리스트로 ChatModel을 호출해 응담을 출력\n",
    "llm = init_chat_model('openai:gpt-4.1-mini')\n",
    "\n",
    "# (role, content) 튜플 형태의 대화 메시지\n",
    "messages =[\n",
    "    ('system', '당신은 친절한 챗봇입니다.'),            # 시스템 프롬프트\n",
    "    ('user','랭체인/랭그래프를 간단히 설명해주세요.')   # 유저 메시지\n",
    "]\n",
    "\n",
    "ai_message=llm.invoke(messages)\n",
    "ai_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "098e704c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'랭체인(LangChain)과 랭그래프(LangGraph)는 둘 다 자연어 처리와 인공지능 분야에서 활용되는 도구입니다.\\n\\n1. **랭체인(LangChain)**  \\n   - 랭체인은 LLM(대형 언어 모델)을 쉽게 활용할 수 있도록 돕는 오픈소스 프레임워크입니다.  \\n   - 다양한 데이터 소스와 연동하거나, 복잡한 작업 흐름(체인)을 만들 수 있게 설계되어 있어, 챗봇, 문서 요약, 질의응답 같은 애플리케이션 개발에 많이 쓰입니다.  \\n   - 개발자가 언어 모델, 메모리, 프롬프트 관리, API 호출 등을 효율적으로 조합할 수 있도록 도와줍니다.\\n\\n2. **랭그래프(LangGraph)**  \\n   - 랭그래프는 언어 모델의 작업 과정을 그래프 형태로 시각화하거나 구조화하는 툴 또는 개념입니다.  \\n   - 복잡한 데이터 흐름이나 작업 단계를 그래프 노드와 엣지로 표현해서, 모델의 이해 및 분석을 쉽게 해줍니다.  \\n   - 이를 통해 모델 동작의 투명성과 디버깅, 최적화를 지원합니다.\\n\\n요약하면, 랭체인은 언어 모델을 활용한 애플리케이션 개발을 돕는 프레임워크라면, 랭그래프는 그 과정이나 작업 흐름을 그래프로 표현해 분석과 시각화를 지원하는 개념 또는 도구입니다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LangChain 메시지 객체(System/Human)로 LLM을 호출해 응답을 출력\n",
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage,ToolMessage\n",
    "llm = init_chat_model('openai:gpt-4.1-mini')\n",
    "\n",
    "# (role, content) 튜플 형태의 대화 메시지\n",
    "messages =[\n",
    "    SystemMessage('당신은 친절한 챗봇입니다.'),            # 시스템 프롬프트\n",
    "    HumanMessage('랭체인/랭그래프를 간단히 설명해주세요.')   # 유저 메시지\n",
    "]\n",
    "\n",
    "ai_message=llm.invoke(messages)\n",
    "ai_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae99c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['product'] input_types={} partial_variables={} template='{product}를 홍보하기 위한 참신한 문구를 작성해 줘'\n",
      "전기차를 홍보하기 위한 참신한 문구를 작성해 줘\n",
      "카메라를 홍보하기 위한 참신한 문구를 작성해 줘\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'물론입니다! 전기차를 홍보하기 위한 참신한 문구 몇 가지를 제안해 드릴게요:\\n\\n1. \"미래를 달리는 힘, 전기로 충전하세요!\"\\n2. \"조용한 혁명, 당신의 드라이브를 바꿉니다.\"\\n3. \"탄소는 덜고, 자유는 더한 전기차의 새 경험.\"\\n4. \"전기로 달리는 세상, 친환경의 시작입니다.\"\\n5. \"속도는 빠르게, 지구는 가볍게—전기차와 함께!\"\\n6. \"소음은 줄이고, 즐거움은 배가하는 친환경 드라이브.\"\\n7. \"환경을 생각하는 당신의 선택, 전기차로 완성하세요.\"\\n8. \"전기차 한 대가 만드는 큰 변화, 지금 시작하세요.\"\\n9. \"내일을 위한 한 걸음, 오늘 전기차에 몸을 싣다.\"\\n10. \"충전만큼 간편한 미래, 전기차와 함께 달려보세요.\"\\n\\n필요한 분위기나 타깃층에 맞춰 더 특화된 문구도 만들어 드릴 수 있습니다!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate으로 프롬프트를 템플릭화해서 상품별 문구를 만들고 LLM을 생성\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 변수 {product}를 포함한 템플릿 생성\n",
    "prompt = PromptTemplate.from_template('{product}를 홍보하기 위한 참신한 문구를 작성해 줘')\n",
    "print(prompt)\n",
    "print(prompt.format(product='전기차'))  # 변수를 채운 완성된 프름프트 문자열\n",
    "print(prompt.format(product='카메라'))  # 변수를 채운 완성된 프롬프트 문자열\n",
    "\n",
    "llm = init_chat_model('openai:gpt-4.1-mini')\n",
    "\n",
    "ai_message=llm.invoke(prompt.format(product='전기차'))\n",
    "ai_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3b69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['domain', 'question'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['domain'], input_types={}, partial_variables={}, template='당신은 {domain}분야의 전문가입니다. 친절히 답해주세요.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question} 한글로 답해주세요.'), additional_kwargs={})]\n",
      "System: 당신은 IT분야의 전문가입니다. 친절히 답해주세요.\n",
      "Human: langsmith 사용법 한글로 답해주세요.\n",
      "안녕하세요! IT 분야 전문가로서 LangSmith 사용법을 한글로 친절하게 설명드리겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## LangSmith란?\n",
      "LangSmith는 언어 모델(Large Language Model, LLM)을 테스트하고 디버깅하며 모니터링할 수 있는 도구입니다. 개발자가 언어 모델의 성능을 쉽게 평가하고 향상시킬 수 있도록 돕습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## LangSmith 사용법\n",
      "\n",
      "### 1. LangSmith 가입 및 API 키 발급\n",
      "- LangSmith 공식 웹사이트에 가입합니다.\n",
      "- 로그인 후 API 키를 발급받습니다.\n",
      "- API 키는 나중에 LangSmith SDK나 HTTP 요청 시 인증용으로 사용됩니다.\n",
      "\n",
      "### 2. SDK 설치\n",
      "LangSmith는 Python SDK를 제공합니다. 터미널(또는 CMD)에서 다음 명령어로 설치하세요.\n",
      "\n",
      "```bash\n",
      "pip install langsmith\n",
      "```\n",
      "\n",
      "### 3. SDK 초기화\n",
      "발급받은 API 키를 사용해 LangSmith 클라이언트를 초기화합니다.\n",
      "\n",
      "```python\n",
      "from langsmith import Client\n",
      "\n",
      "client = Client(api_key=\"your_api_key_here\")\n",
      "```\n",
      "\n",
      "### 4. 언어 모델 인터랙션 기록하기\n",
      "LangSmith에서는 LLM에 입력한 프롬프트와 결과값, 메타데이터 등을 기록할 수 있습니다.\n",
      "\n",
      "```python\n",
      "from langsmith import Client, Prompt, Run\n",
      "\n",
      "client = Client(api_key=\"your_api_key_here\")\n",
      "\n",
      "prompt = Prompt(text=\"안녕하세요, 오늘 날씨가 어떻나요?\")\n",
      "run = Run(prompt=prompt)\n",
      "\n",
      "# 모델에서 응답을 받아온 예시\n",
      "response = \"오늘은 맑고 기온은 20도입니다.\"\n",
      "\n",
      "# 응답 저장\n",
      "run.response = response\n",
      "\n",
      "# LangSmith에 기록 전송\n",
      "client.create_run(run)\n",
      "```\n",
      "\n",
      "### 5. 대시보드에서 기록 확인\n",
      "- LangSmith 웹사이트에 로그인 후 대시보드에서 기록한 대화 세션, 프롬프트, 결과를 모니터링 할 수 있습니다.\n",
      "- 결과를 분석하며 문제점이나 개선점을 파악할 수 있습니다.\n",
      "\n",
      "### 6. 추가 기능\n",
      "- **프롬프트 템플릿 관리**: 자주 사용하는 프롬프트를 템플릿으로 저장해 재사용 가능\n",
      "- **자동화 테스트**: 여러 프롬프트 테스트를 자동으로 수행하고 결과 비교\n",
      "- **사용자 정의 메타데이터**: 프롬프트와 응답에 메타데이터 추가 가능\n",
      "\n",
      "---\n",
      "\n",
      "## 참고 자료\n",
      "- 공식 문서: [https://docs.langsmith.com](https://docs.langsmith.com)\n",
      "- GitHub: [https://github.com/langsmith/langsmith-sdk](https://github.com/langsmith/langsmith-sdk)\n",
      "\n",
      "---\n",
      "\n",
      "필요하시면 예제 코드나 구체적인 기능 대해 더 알려드릴 수 있습니다. 편하게 말씀해주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 여러 메시지(role, content)를 템플릿으로 구성\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system','당신은 {domain}분야의 전문가입니다. 친절히 답해주세요.'),\n",
    "    ('user','{question} 한글로 답해주세요.'),\n",
    "])\n",
    "\n",
    "print(chat_prompt)\n",
    "print(chat_prompt.format(domain='IT',question='langsmith 사용법'))\n",
    "\n",
    "llm = init_chat_model('openai:gpt-4.1-mini')\n",
    "\n",
    "ai_message = llm.invoke(chat_prompt.format(domain='IT', question='langsmith 사용법'))\n",
    "print(ai_message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1083bcf0",
   "metadata": {},
   "source": [
    "## Output Parser\n",
    "객체의 출력에서 실제 값부분을 가져와 후처리 작업 담당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163b50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['달걀', '고구마', '대파', '쪽파']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CommaSeparatedListOutputParser : 콤마 구분 문자열 -> 리스트 변환 파서\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()   # 객체 생성\n",
    "model_output = '달걀, 고구마, 대파, 쪽파'   # 모델의 출력\n",
    "parser.parse(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b5f632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
      "input_variables=['n', 'subject'] input_types={} partial_variables={'format_instruction': 'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'} template='{subject} 팀 {n}개를 작성해주세요. \\n(지시사항: {format_instruction})'\n",
      "프로야구 팀 5개를 작성해주세요. \n",
      "(지시사항: Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`)\n"
     ]
    }
   ],
   "source": [
    "format_instruction = parser.get_format_instructions()\n",
    "print(format_instruction)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    # subject/n + 지시사항을 포함한 템플릿\n",
    "    template='{subject} 팀 {n}개를 작성해주세요. \\n(지시사항: {format_instruction})',\n",
    "    input_variables=['subject','n'],    # 사용자가 채울 변수들\n",
    "    partial_variables={'format_instruction':format_instruction} # 고정으로 주입할 변수\n",
    ")\n",
    "\n",
    "print(prompt)   # 템필릿 구조\n",
    "print(prompt.format(subject='프로야구',n=5))    # 변수를 채운 최종 프롬프트 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95f943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='프로야구 팀 5개를 작성해주세요. \\n(지시사항: Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`)'\n",
      "두산 베어스, 삼성 라이온즈, 롯데 자이언츠, 기아 타이거즈, 한화 이글스\n",
      "['두산 베어스', '삼성 라이온즈', '롯데 자이언츠', '기아 타이거즈', '한화 이글스']\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> LLM 호출 -> OutputParser로 리스트 변환\n",
    "input = prompt.invoke({'subject':'프로야구','n':5}) # 변수 (subject,n)을 넣어 프롬프트 메시지 생성\n",
    "print(input)\n",
    "\n",
    "llm = init_chat_model('openai:gpt-4.1-mini')\n",
    "ai_message=llm.invoke(input)\n",
    "print(ai_message.content)\n",
    "\n",
    "parser=CommaSeparatedListOutputParser()\n",
    "output=parser.invoke(ai_message)        # LLM 응답 콤마 기준으로 파싱 -> 파이썬 리스트\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19ead5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['키움히어로즈', 'LG트윈스', '삼성라이온즈', '롯데자이언츠', '한화이글스']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCEL(파이프)로 Prompt -> LLM -> OutputParser를 하나의 체인으로 연결해 실행\n",
    "chain = prompt | llm | parser   # 프롬프트 -> 모델 -> 파서\n",
    "chain.invoke({'subject':'프로야구','n':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39731a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'겨울 제철 과일로는 다음과 같은 것들이 있어요:\\n\\n1. **감귤류 과일**: 귤, 오렌지, 한라봉, 레몬 등 비타민 C가 풍부해 감기 예방에 좋아요.\\n2. **사과**: 달고 아삭한 식감이 특징이며, 겨울철에도 신선하게 즐길 수 있어요.\\n3. **배**: 수분이 많고 시원한 맛이 겨울철 건조한 날씨에 좋아요.\\n4. **키위**: 비타민 C가 풍부하고 새콤달콤해 겨울철 간식으로 인기예요.\\n5. **석류**: 항산화 성분이 많아 겨울철 면역력 강화에 도움이 돼요.\\n6. **감**: 단 맛이 진하고 포만감을 줘서 겨울 간식으로 적합해요.\\n\\n겨울철에는 이 과일들을 신선하게 즐기면 건강 유지에 도움이 됩니다!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StrOutputParser : 모델 응답을 가공없이 문자열로 받아 출력\n",
    "from langchain_core.output_parsers import StrOutputParser   # AIMessage -> str(content) 변환해주는 파서\n",
    "parser=StrOutputParser()    # 파서 객체 생성\n",
    "chain = llm | parser        # LLM 출력 -> 문자열로 파싱\n",
    "chain.invoke('겨울 제철 과일은 뭐가 있어?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9401ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return a JSON object.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'books': [{'title': '인공지능: 현대적 접근',\n",
       "   'authors': ['스튜어트 러셀', '피터 노빅', '전병곤(역자)'],\n",
       "   'publisher': '한빛미디어',\n",
       "   'year': 2016,\n",
       "   'description': '인공지능 분야의 고전적 교재로, AI의 전반적인 이론과 실습을 다룬다.'},\n",
       "  {'title': '파이썬으로 배우는 인공지능',\n",
       "   'authors': ['박해선'],\n",
       "   'publisher': '한빛아카데미',\n",
       "   'year': 2018,\n",
       "   'description': '파이썬을 활용해 인공지능과 머신러닝 기초를 배우기에 적합한 입문서.'},\n",
       "  {'title': '딥러닝 입문',\n",
       "   'authors': ['조르디 토레스', '김성훈(역자)'],\n",
       "   'publisher': '에이콘출판',\n",
       "   'year': 2017,\n",
       "   'description': '딥러닝의 기본 개념과 구현 방법을 쉽게 설명한 책.'},\n",
       "  {'title': '케라스로 배우는 딥러닝',\n",
       "   'authors': ['프랑소와 숄레', '윤인성(역자)'],\n",
       "   'publisher': '한빛미디어',\n",
       "   'year': 2018,\n",
       "   'description': '케라스 라이브러리를 사용하여 딥러닝 모델을 구축하는 방법을 소개.'},\n",
       "  {'title': '인공지능과 머신러닝',\n",
       "   'authors': ['송영환'],\n",
       "   'publisher': '위키북스',\n",
       "   'year': 2020,\n",
       "   'description': '인공지능과 머신러닝의 주요 개념과 최신 동향을 다룬 실무서.'}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JsonOutputParser : 모델의 json 문자열 응답을 파이썬 객체 dict/list로 변환(파싱)하는 파서\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "format_instruction=parser.get_format_instructions() # 모델에게 JSON으로 답하라고 지시하는 문구 생성\n",
    "print(format_instruction)\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    # subjecet/n + JSON 지시사항 포함\n",
    "    template='{subject}분야의 유명한 한국어 책 {n}권 정보를 제공해주세요.\\n지시사항: {format_instruction})',\n",
    "    input_variables=['subject','n'],    # 사용자가 채울 변수들\n",
    "    partial_variables={'format_instruction':format_instruction} # 고정으로 주입할 변수\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser   # 체인 : 프롬프트 -> LLM -> JSON 파서\n",
    "result = chain.invoke({'subject':'인공지능','n':5})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b76ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Book\": {\"properties\": {\"title\": {\"title\": \"Title\", \"type\": \"string\"}, \"author\": {\"title\": \"Author\", \"type\": \"string\"}, \"publisher\": {\"title\": \"Publisher\", \"type\": \"string\"}, \"year\": {\"default\": null, \"title\": \"Year\", \"type\": \"integer\"}, \"description\": {\"title\": \"Description\", \"type\": \"string\"}}, \"required\": [\"title\", \"author\", \"publisher\", \"description\"], \"title\": \"Book\", \"type\": \"object\"}}, \"properties\": {\"books\": {\"items\": {\"$ref\": \"#/$defs/Book\"}, \"title\": \"Books\", \"type\": \"array\"}}, \"required\": [\"books\"]}\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BookList(books=[Book(title='인공지능: 현대적 접근', author='Stuart Russell, Peter Norvig, 김성훈 외 역', publisher='한빛미디어', year=2016, description='인공지능 분야의 고전이자 대표적인 교재로, 인공지능의 이론과 다양한 응용 분야에 대한 폭넓은 내용을 다룬 책입니다.'), Book(title='파이썬 머신러닝 완벽 가이드', author='권철민', publisher='한빛미디어', year=2017, description='파이썬을 활용한 머신러닝 실습서로, 기본 개념부터 실전 예제까지 단계별로 학습할 수 있는 책입니다.'), Book(title='딥러닝 입문: 파이토치', author='정영근', publisher='위키북스', year=2020, description='파이토치 프레임워크를 활용하여 딥러닝의 기본 개념과 모델 구현 방법을 설명하는 입문서입니다.'), Book(title='인공지능과 머신러닝', author='이광근', publisher='교학사', year=2018, description='인공지능과 머신러닝의 기본 원리 및 알고리즘을 다루며, 교육 현장에 적합한 교재로도 활용됩니다.'), Book(title='트렌드 코리아 2023: 인공지능과 미래사회', author='김난도 외', publisher='서울대학교 출판문화원', year=2022, description='인공지능이 가져올 미래사회 변화를 분석하고 다양한 산업 및 일상생활 속 AI 트렌드를 소개하는 책입니다.')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PydanticOutputParser : 스키마(형식)를 강제해서 구조화된 책 목록을 받는 코드\n",
    "from pydantic import BaseModel  # 데이터 스키마(모델) 정의용\n",
    "from langchain_core.output_parsers import PydanticOutputParser  # LLM출력 -> Pydantic 객체로 검증/변환\n",
    "from typing import List # 리스트 타입 힌트용\n",
    "\n",
    "# 책 1권마다의 스키마 정의\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    author: str\n",
    "    publisher: str\n",
    "    year: int = None    # 출간연도(없어도 상관없음)\n",
    "    description: str\n",
    "    \n",
    "# 책 여러권을 담는 스키마 정의\n",
    "class BookList(BaseModel):\n",
    "    books: List[Book]\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=BookList) # 출력이 BookList 형태가 되도록 파서 생성\n",
    "format_instruction=parser.get_format_instructions()     # 스키마대로 출력하도록 만드는 지시문\n",
    "print(format_instruction)\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    # subjecet/n + JSON 지시사항 포함\n",
    "    template='{subject}분야의 유명한 한국어 책 {n}권 정보를 제공해주세요.\\n지시사항: {format_instruction})',\n",
    "    input_variables=['subject','n'],    # 사용자가 채울 변수들\n",
    "    partial_variables={'format_instruction':format_instruction} # 고정으로 주입할 변수\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser   # 체인 : 프롬프트 -> LLM -> Pydantic 파서\n",
    "result = chain.invoke({'subject':'인공지능','n':5}) # 파싱/검증된 BookList 객체 반환\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d3d30b",
   "metadata": {},
   "source": [
    "- Book / BookList는 pydantic.BaseModel을 상속한 스키마(데이터 모델)이다.\n",
    "- result는 그 스키마로 만들어진 Pydantic 객체(인스턴스)\n",
    "\n",
    "- 사용하면\n",
    "    - 필드가 있는지 검사\n",
    "    - 타임 검사/변환\n",
    "    - 구조가 맞는지 검사\n",
    "\n",
    "- dictionary와 차이점\n",
    "    - dict : ㅇ무키나 들어갈수 있고, 타입도 상관없다.\n",
    "    - Pydatic 객체 : 정해진 키/타입만 허용. 틀리면 잡아줌(검증)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0091af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BookList(books=[Book(title='인공지능: 현대적 접근', author='스튜어트 러셀, 피터 노빅', publisher='한빛미디어', year=2016, description='인공지능 분야의 대표적인 교재로, 기초부터 심화까지 인공지능 기술과 이론을 폭넓게 다룸.'), Book(title='딥러닝 입문', author='조르디 토렌티', publisher='웨일북', year=2019, description='딥러닝의 기본 개념과 최신 연구를 한국어로 쉽게 소개하는 입문서.'), Book(title='파이썬으로 배우는 머신러닝, 딥러닝 실전 개발 입문', author='천인국', publisher='한빛미디어', year=2020, description='파이썬을 이용해 머신러닝과 딥러닝 기법을 실습 중심으로 배울 수 있는 책.'), Book(title='케라스 창시자에게 배우는 딥러닝', author='프랑소와 숄레', publisher='이비락', year=2020, description='케라스 개발자가 직접 설명하는 딥러닝 기초부터 실전 구현까지 다룸.'), Book(title='파이썬 인공지능 프로젝트', author='장창민', publisher='한빛아카데미', year=2021, description='다양한 인공지능 프로젝트 예제로 실무에 활용할 수 있는 내용을 담고 있음.')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with_structured_output() : Pydantic 스키마를 받아 구조화된 결과를 바로 받는다\n",
    "prompt=PromptTemplate(\n",
    "    # subjecet/n + JSON 지시사항 포함\n",
    "    template='{subject}분야의 유명한 한국어 책 {n}권 정보를 제공해주세요.)',\n",
    "    input_variables=['subject','n'],    # 사용자가 채울 변수들\n",
    ")\n",
    "\n",
    "chain = prompt | llm.with_structured_output(BookList)   # LLM의 출력이 BookList 스키마를 따르도록 래핑\n",
    "result = chain.invoke({'subject':'인공지능','n':5}) # 파싱/검증된 BookList 객체 반환\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eaac33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

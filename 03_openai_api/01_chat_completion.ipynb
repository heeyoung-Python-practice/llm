{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5ecfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI                 # OpenAI API를 사용하기 위한 클라이언트 클래스\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv('openai_key')\n",
    "client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd952076",
   "metadata": {},
   "source": [
    "# 대화내역 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e089a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-D3bbAGv15cwvykNsMvpo9eJvwqqDA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='물론이야! 세 줄로 요약해볼게.\\n\\n1. GPT는 트랜스포머의 디코더 구조를 기반으로 만들어졌어.  \\n2. 대규모 텍스트로 사전학습하고, 다양한 작업에 적용 가능해.  \\n3. 모델이 커지면서 더 자연스럽고 다양한 언어 능력을 갖추게 됐어.  \\n\\n궁금한 거 있으면 또 물어봐!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1769751884, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_e01c6f58e1', usage=CompletionUsage(completion_tokens=94, prompt_tokens=624, total_tokens=718, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-4.1-mini',\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'system',                    # 시스템 역할: 챗봇의 성격/규칙 지정\n",
    "            'content': '너는 친절한 챗봇입니다.'  # 친절한 톤으로 응답하도록 지시\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',                      # 사용자 발화 1\n",
    "            'content': '안녕, 나는 LLM을 공부하는 학생이야. 반갑다~'\n",
    "        },\n",
    "        {\n",
    "            'role': 'assistant',                 # (이전 대화가 있었다는 가정) 어시스턴트의 답변을 히스토리로 제공\n",
    "            'content': '안녕! 만나서 반가워~ LLM 공부하고 있다니 멋지다! 어떤 분야에 관심이 있는지 말해줄래? 내가 도움이 될 수 있으면 좋겠어.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',                      # 사용자 발화 2(질문)\n",
    "            'content': 'gpt모델은 트랜스포머로부터 어떻게 발전된거야?'\n",
    "        },\n",
    "        {\n",
    "            'role': 'assistant',                 # (이전 답변) 긴 설명을 히스토리로 제공\n",
    "            'content': '''\n",
    "            좋은 질문이야! GPT 모델은 트랜스포머(Transformer) 아키텍처를 기반으로 발전했어. 간단히 설명할게.\n",
    "\n",
    "            1. **트랜스포머(Transformer)**\n",
    "            2017년에 \"Attention is All You Need\" 논문에서 소개된 트랜스포머는 자연어 처리의 혁신적인 모델 구조야. 이전 RNN이나 LSTM과 달리, 순차적인 계산 없이도 병렬 처리가 가능하고, '셀프 어텐션(Self-Attention)' 메커니즘을 사용해 문맥을 효율적으로 이해할 수 있어.\n",
    "\n",
    "            2. **GPT (Generative Pre-trained Transformer)**\n",
    "            GPT는 트랜스포머의 '디코더' 부분을 기반으로 한 모델이야. OpenAI가 처음 발표한 GPT는 대규모 텍스트 데이터에 대해 '언어 모델링' 방식으로 사전학습(pre-training)을 하고, 이후 특정 작업에 맞게 미세조정(fine-tuning)하는 방식을 사용했어.\n",
    "\n",
    "            3. **주요 발전 포인트**\n",
    "            - **사전학습과 미세조정**: GPT는 트랜스포머를 이용해 방대한 텍스트를 예측하는 작업으로 사전학습하고, 이후 다양한 언어 처리 작업에 적용할 수 있어.\n",
    "            - **규모 확장**: GPT-2, GPT-3, 그리고 최신 GPT-4로 갈수록 모델 크기와 학습 데이터 양이 크게 늘어나면서, 더 자연스럽고 다재다능한 언어 능력을 갖추게 됐어.\n",
    "            - **제로샷/원샷 학습 능력**: 큰 모델로 발전하면서 GPT는 별도 미세조정 없이도 (제로샷) 또는 적은 예시만으로도 (원샷/퓨샷) 다양한 작업을 수행할 수 있게 되었어.\n",
    "\n",
    "            정리하자면, GPT는 트랜스포머 아키텍처의 강력한 특징들을 활용해, 대규모 사전학습과 점차 확장된 모델 크기를 통해 자연어 생성 및 이해 능력을 크게 향상시킨 모델이라고 할 수 있어.\n",
    "\n",
    "            더 궁금한 점 있으면 언제든 물어봐!\n",
    "            '''\n",
    "        },\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : '와 대단하구나! 세 줄로 요약해 줘.'\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,  # 창의성 (높을수록 창의적)\n",
    "    top_p=1,        # Top-p 샘플링 범위(1이면 제한없음)\n",
    "    max_completion_tokens=4096  # 최대 출력 토큰 수\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff2a90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'물론이야! 세 줄로 요약해볼게.\\n\\n1. GPT는 트랜스포머의 디코더 구조를 기반으로 만들어졌어.  \\n2. 대규모 텍스트로 사전학습하고, 다양한 작업에 적용 가능해.  \\n3. 모델이 커지면서 더 자연스럽고 다양한 언어 능력을 갖추게 됐어.  \\n\\n궁금한 거 있으면 또 물어봐!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793639fa",
   "metadata": {},
   "source": [
    "### 사용자의 입력을 반복적으로 받아 대화하는 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3f035a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종료하려면, exit를 입력하세요\n",
      "\n",
      "Assistant:안녕하세요! 무엇을 도와드릴까요?\n",
      "Assistant:죄송하지만 저는 실시간 날씨 정보를 제공할 수 없습니다. 현재 위치의 정확한 날씨를 알고 싶으시면 기상청 웹사이트나 날씨 애플리케이션을 확인해 보시는 것을 추천드립니다. 도움이 필요하시면 언제든 말씀해 주세요!\n",
      "Assistant:필요한 정보가 있으면 언제든 말씀해 주세요! 도움이 될 수 있어서 기쁩니다.\n",
      "대화를 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role':'system','content':'당신은 지혜로운 챗봇입니다.'}\n",
    "]\n",
    "\n",
    "print('종료하려면, exit를 입력하세요\\n')\n",
    "\n",
    "while True:\n",
    "    user_input = input('User: ')\n",
    "    \n",
    "    if user_input.lower().strip() == 'exit':\n",
    "        print('대화를 종료합니다.')\n",
    "        break\n",
    "    \n",
    "    messages.append({'role': 'user', 'content' : user_input})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-4.1-mini',\n",
    "        messages = messages,\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        max_completion_tokens=4096\n",
    "    )\n",
    "    assistant_message = response.choices[0].message.content\n",
    "    print(f'Assistant:{assistant_message}')\n",
    "    messages.append({'role' : 'assistant','content':assistant_message})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66bca7",
   "metadata": {},
   "source": [
    "- 서비스에서 대화 저장을 처리하는 방식\n",
    "    - DB에 저장 (일반적)\n",
    "        - RDB(PostgreSQL/MySQL) : 유저/세선/메시지 관계를 함께 저장\n",
    "        - NoSQL(MongoDB 등) : 문서 형태로 대화를 한번에 저장\n",
    "    - 캐시에 저장(속도) + DB에 영구 저장(혼합)\n",
    "        - Redis에 최근 N개의 메시지를 캐시로 두고 빠르게 저장\n",
    "        - 일정 주기/이벤트 기준으로 DB에 영구 저장\n",
    "    - 파일에 저장\n",
    "        - JSON 파일 등으로 로컬에 저장\n",
    "        - 붙여서 사용하는 가벼운 DB가 파일형태로 저장되는 경우\n",
    "\n",
    "- 서비스 운영시에 고려사항\n",
    "    - 전체 대화를 매번 모델에 다 보내게 되면 비용/속도 문제가 생긴다.\n",
    "        - 최근 N개만 보낸다거나\n",
    "        - 중간중간에 요약(summary)을 만들어 저장하고 요약본 + 최근 대화 형태로 컨텍스트 구성\n",
    "    - 개인정보\n",
    "        - DB 접근 암호화, 로그 마스킹\n",
    "        - API/KEY 등은 대화메시지에 저장하지 않음\n",
    "    - RAG 같은 검색형 기능들을 추가할 경우\n",
    "        - 전체 대화를 DB에 저장 + 중요한 메시지는 벡터 DB에 임베딩 저장해서 예전에 대화했던 내용과 관련된 내용이 나오면 검색해서 커텍스트에 추가해준다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e7191",
   "metadata": {},
   "source": [
    "### Chat Completions를 스트리밍으로 받아 한 글자씩 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8684477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 스트림 테스트를 위한 아주 긴 답변을 준비해 드리겠습니다. 다양한 주제와 정보들을 포함해서 최대한 풍부하고 상세하게 작성해 보겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "인류 역사의 흐름 속에서 기술의 발전은 놀라운 속도로 진행되어 왔으며, 그 결과 현대 사회는 정보화 시대에 접어들어 엄청난 양의 데이터를 생성하고 처리하는 단계에 이르렀습니다. 특히, 인터넷과 컴퓨터 기술의 발달은 전 세계를 연결하는 거대한 네트워크를 형성하여 사람들 간의 소통 방식을 근본적으로 바꾸어 놓았습니다. 초기의 아날로그 통신 기술은 디지털 기술로 대체되면서 정보의 전달 속도와 정확성이 극적으로 향상되었으며, 이것이 오늘날 우리가 누리는 다양한 온라인 서비스와 플랫폼의 기반이 되었습니다.\n",
      "\n",
      "예를 들어, 과거에는 손편지나 전화 통화가 주를 이루었으나, 현재는 이메일, 소셜 미디어, 화상 통화, 메시징 앱 등 다양한 디지털 채널을 통해 실시간으로 전 세계 어디서나 소통이 가능합니다. 이와 같은 기술적 진보는 비즈니스, 교육, 의료, 엔터테인먼트 등 여러 분야에 혁신을 불러왔으며, 원격 근무와 온라인 학습 같은 새로운 라이프스타일을 가능하게 했습니다.\n",
      "\n",
      "더불어 인공지능과 머신러닝 기술의 발전은 데이터 분석과 자동화를 통해 많은 일들을 더 효율적이고 정밀하게 처리할 수 있게 해 줍니다. 인공지능은 이미지 인식, 자연어 처리, 자율 주행차, 개인 맞춤형 추천 시스템 등 우리 일상생활 곳곳에 스며들어 있으며, 앞으로도 그 영향력은 더욱 커질 것으로 전망됩니다. 그러나 이러한 변화는 동시에 개인정보 보호, 윤리적 문제, 기술 격차와 같은 사회적 이슈도 동반하고 있습니다.\n",
      "\n",
      "한편, 지속 가능한 발전과 환경 보호에 대한 관심도 점차 높아지고 있는데, 이는 기후 변화와 자원 고갈 문제에 대한 인식이 확대되었기 때문입니다. 각국은 친환경 에너지 사용을 확대하고 탄소 배출을 줄이기 위한 정책을 시행하며, 기업들도 ESG(Environmental, Social, Governance) 경영을 통해 사회적 책임을 다하려는 움직임이 활발합니다. 기술 역시 이러한 목표를 지원하는 역할을 하며, 예를 들어 스마트 그리드, 재생 에너지 관리 시스템, 전기 자동차 등이 발전하고 있습니다.\n",
      "\n",
      "이와 같은 복합적인 사회 변화 속에서 개인과 공동체는 새로운 기회와 도전을 경험하며 적응해 나가고 있습니다. 교육에서는 디지털 리터러시가 필수 요소로 자리 잡았으며, 평생 학습이 강조되고 있습니다. 건강 관리 분야에서는 웨어러블 디바이스와 원격 진료가 보편화되어 개인 맞춤형 건강 관리가 가능해졌습니다. 또한 문화와 예술은 디지털 미디어를 통해 전 세계적으로 공유되고 교류되며, 새로운 창작과 표현의 장을 열어가고 있습니다.\n",
      "\n",
      "끝으로, 이러한 변화들로 인해 우리는 끊임없이 배우고 변화에 대응해야 하는 시대에 살고 있다는 점을 기억하는 것이 중요합니다. 기술의 이점과 위험성을 균형 있게 이해하고, 인간 중심의 가치와 윤리를 기반으로 한 발전 방향을 모색하는 것이 앞으로의 사회가 나아가야 할 길일 것입니다.\n",
      "\n",
      "---\n",
      "\n",
      "필요하신 다른 주제가 있거나 특정 부분에 대해 더 자세한 설명이 필요하시면 언제든지 말씀해 주세요!"
     ]
    }
   ],
   "source": [
    "# 스트림처리 : 응답을 한 번에 받지 않고 조각(chunk) 단위로 실시간 수신\n",
    "stream = client.chat.completions.create(\n",
    "    model = 'gpt-4.1-mini',\n",
    "    messages=[{'role':'user','content':'나 스트림테스트 할 거니까, 아주 긴 답변을 해줘.'}],\n",
    "    max_completion_tokens=2000,\n",
    "    stream=True     # 스트리밍 모두 확성화(True면 chunk 단위로 반환)\n",
    ")\n",
    "\n",
    "for chunk in stream:    # 스트림에서 chunk를 하나씩 순회하면서 수신\n",
    "    content = chunk.choices[0].delta.content    # 이번 chunk에 새로 추가된 텍스트(delta)만 추출\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59a918",
   "metadata": {},
   "source": [
    "# 스트리밍 응답으로 실시간 출력되는 콘솔 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de180f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종료하려면, exit를 입력하세요\n",
      "\n",
      "Assistant : 그럼 가벼운 농담 하나 해볼게요!\n",
      "\n",
      "왜 수학책은 항상 슬플까요?  \n",
      "답: 문제들이 너무 많아서요!  \n",
      "\n",
      "더 듣고 싶으면 언제든 말해줘요!\n",
      "대화를 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role':'system','content':'당신은 지혜로운 챗봇입니다.'}\n",
    "]\n",
    "\n",
    "print('종료하려면, exit를 입력하세요\\n')\n",
    "\n",
    "while True:\n",
    "    user_input = input('User: ')\n",
    "    \n",
    "    if user_input.lower().strip() == 'exit':\n",
    "        print('대화를 종료합니다.')\n",
    "        break\n",
    "    \n",
    "    messages.append({'role': 'user', 'content' : user_input})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-4.1-mini',\n",
    "        messages = messages,\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        max_completion_tokens=4096,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # 스트림 출력처리 : chunk가 도착할 때마다 바로 출력하고 전체 답변을 누적\n",
    "    print(f'Assistant : ',end='')\n",
    "    assistant_message = ''          # 전체 답변을 누적할 변수\n",
    "    for chunk in response:          # 스트리밍 모드로 도착한 chunk 단위로 순회\n",
    "        content = chunk.choices[0].delta.content    # 이번 chunk에 새로 추가된 텍스트(delta)\n",
    "        if content is not None:\n",
    "            print(content, end='')      # 줄바꿈 없이 실시간으로 이어서 출력\n",
    "            assistant_message += content\n",
    "    print()\n",
    "\n",
    "    messages.append({'role' : 'assistant','content':assistant_message})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a4b64",
   "metadata": {},
   "source": [
    "# token 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78491c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tiktoken) (2026.1.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2026.1.4)\n",
      "Downloading tiktoken-0.12.0-cp312-cp312-win_amd64.whl (878 kB)\n",
      "   ---------------------------------------- 0.0/878.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 878.7/878.7 kB 38.5 MB/s  0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0633e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Encoding 'cl100k_base'>\n",
      "14\n",
      "<Encoding 'o200k_base'>\n",
      "10\n",
      "<Encoding 'o200k_base'>\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import tiktoken     # 텍스트를 토큰 단위로 인코딩/계산하는 OpenAI 토크나이저 라이브러리\n",
    "\n",
    "gpt35 = tiktoken.encoding_for_model('gpt-3.5')  # GPT 3.5에 대응되는인코딩(토크나이저) 가져옴\n",
    "print(gpt35)\n",
    "print(len(gpt35.encode('아버지가 방에 들어가십니다.'))) # 문장을 토크느로 쪼갠 후 토큰 개수 확인\n",
    "\n",
    "gpt4o = tiktoken.encoding_for_model('gpt-4o')\n",
    "print(gpt4o)\n",
    "print(len(gpt4o.encode('아버지가 방에 들어가십니다.')))\n",
    "\n",
    "gpt41 = tiktoken.encoding_for_model('gpt-4.1')\n",
    "print(gpt41)\n",
    "print(len(gpt41.encode('아버지가 방에 들어가십니다.')))\n",
    "\n",
    "# gpt52 = tiktoken.encoding_for_model('gpt-5.2')    # tiktokenㅜ에 정보가 없으면 keyError가 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1746b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_headline(headline, /, *, model='gpt-4.1-mini', temperature=1, top_p=1, max_completion_tokens=2048):\n",
    "    response = client.chat.completions.create(                 # OpenAI Chat Completions API 호출\n",
    "        model=model,                                           # 사용할 모델 지정\n",
    "        messages=[                                             # 대화 메시지 목록\n",
    "            {\n",
    "                \"role\": \"system\",                              # 시스템 역할: 모델의 페르소나/규칙 정의\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",                        # 텍스트 타입 메시지\n",
    "                        \"text\": \"기자들이 송고한 제목에서 맞춤법/문법/의미/어조등을 고려해 최상의 뉴스제목을 뽑아내는 20년 경력의 뉴스제목교정가이다.\\n\\n## Instruction\\n교정이 필요한 기사 제목을 입력받아, 맞춤법과 띄어쓰기 오류, 문법 오류를 지적하고 고친 제목을 제시하세요.  \\n아래 단계로 진행합니다:  \\n1. 입력된 기사 제목을 면밀히 분석하여 맞춤법 오류, 띄어쓰기 실수, 문법 오류 등 문제점을 찾아 지적 항목으로 정리합니다.  \\n2. 문제점을 모두 고친 교정된 기사 제목을 결과로 제시합니다.  \\n3. 교정이 필요한 부분과 수정결과를 교정이유항목에 작성해주세요.\\n4. 기사 제목에 오류가 여러 개 있을 경우, 각 오류를 번호를 매겨 명확히 구분하여 지적합니다.\\n5. 독자의 관심을 끌수 있도록 간결하면서도 임팩트 있는 표현을 사용하세요.\\n6. 어조가 지나치게 감정적이거나 부정적이라면, 적절히 중립적 표현을 사용하세요.\\n7. 비속어/욕설등이 포함되어 있다면 이를 제거하고, 의미가 전달될수 있는 적절한 표현으로 수정하세요. \\n\\n## Output Format\\n- 원래제목: [송고한 기사제목]\\n- 교정제목: [교정한 기사제목]\\n- 교정 이유:\\n  1. [교정한 부분과 이유]\\n  2. [교정한 부분과 이유]\\n\\n## Examples\\n<예시1>  \\n입력: \\\"코로나19 백신접종율 높히기 위한 대안마련 필요하다\\\"  \\n출력:  \\n- 원래제목: [송고한 기사제목]\\n- 교정제목: \\\"코로나19 백신 접종률 높이기 위한 대안 마련 시급\\\"\\n- 교정 이유:\\n   1. '접종율'은 '접종률'이 맞는 표기입니다.\\n   2. '높히기'는 '높이기'로, 맞춤법 오류입니다.\\n   3. '대안마련'은 붙여쓰지 않고 '대안 마련'으로 띄어 써야 맞습니다.\\n   4. 간결한 어미수정\\n\\n<예시2>  \\n입력: \\\"정부, 연금개혁 지방화 시대 맞춰 적극 나서야한다\\\"  \\n출력:  \\n- 원래제목: [송고한 기사제목]\\n- 교정제목: \\\"정부, 연금개혁 지방화 시대 맞춰 적극 나서야\\\"\\n- 교정 이유:\\n  - 간결한 어미 수정\\n\"  \n",
    "                                                                # 제목 교정 전문가 역할 + 상세 규칙 프롬프트\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",                                # 사용자 역할: 실제 입력 데이터\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",                        # 텍스트 입력\n",
    "                        \"text\": f\"입력: {headline}\"            # 함수 인자로 받은 기사 제목(헤드라인)\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        response_format={\"type\": \"text\"},                      # 응답을 순수 텍스트로 받음\n",
    "        temperature=temperature,                               # 생성 다양성 조절\n",
    "        max_completion_tokens=max_completion_tokens,           # 최대 응답 토큰 수\n",
    "        top_p=top_p,                                           # 확률 질량 기반 샘플링\n",
    "        frequency_penalty=0,                                   # 반복 패널티 없음\n",
    "        presence_penalty=0,                                    # 새로운 주제 유도 패널티 없음\n",
    "        store=False                                            # 서버 저장 비활성화\n",
    "    )\n",
    "    return response.choices[0].message.content                 # 모델이 생성한 최종 결과 반환\n",
    "\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "017e51e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'식자재 배달 기사인 60대 남성 A씨가 3년간 약 8억 2000만원 상당의 갈비탕 5만 3840개를 상습 절도한 혐의로 징역 8개월을 선고받았다. A씨는 재고 파악이 소홀한 점을 이용해 범행을 저질렀으며, 훔친 갈비탕을 내연녀인 60대 여성 B씨에게 전달했다. B씨는 훔친 사실을 알면서도 384회에 걸쳐 갈비탕을 판매해 약 7500만원을 챙겼고, 이에 대해 징역 6개월 실형이 선고됐다. A씨는 B씨에게 매달 300만원 상당의 생활비를 지원했으며, 재판부는 범행 동기가 생활비 부족이라는 주장을 받아들이지 않고, 피해 규모와 죄질을 고려해 실형을 선고했다.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "식자재 배달 기사로 일하며 3년간 약 8억원 치의 갈비탕을 빼돌린 남성과 이를 팔아 금전을 챙긴 그의 내연녀가 모두 실형을 선고받았다.\n",
    "\n",
    "30일 법조계 등에 따르면 서울북부지법 형사9단독(장원정 판사)은 최근 상습절도 혐의로 기소된 60대 남성 A씨에게 징역 8개월을 선고했다. 상습장물양도 혐의로 함께 재판에 넘겨진 60대 여성 B씨 역시 징역 6개월의 실형 선고를 받았다.\n",
    "\n",
    "식자재 배달 기사로 일하며 3년간 약 8억원 치의 갈비탕을 빼돌린 남성과 이를 팔아 금전을 챙긴 그의 내연녀가 모두 실형을 선고받았다. 본 기사와 무관한 이미지.\n",
    "\n",
    "\n",
    "A씨는 지난 2022년 1월부터 지난해 3월까지 서울 도봉구 소재 한 회사 물류창고에서 갈비탕 5만 3840개를 상습적으로 훔친 혐의로 재판에 넘겨졌다.\n",
    "\n",
    "그는 담당자가 재고 파악을 수시로 하지 않는 점을 이용해 이 같은 범행을 저질렀으며 그가 훔친 갈비탕은 약 8억 2000만원 상당인 것으로 파악됐다.\n",
    "\n",
    "A씨는 이 같은 방식으로 훔친 갈비탕을 자신의 내연녀인 B씨에게 전달했다. B씨는 A씨로부터 받은 갈비탕이 훔친 물건이라는 것을 알면서도 불특정 다수에게 판매해 금전을 챙겼다.\n",
    "\n",
    "B씨는 총 384회에 걸쳐 갈비탕을 팔아 약 7500만원을 챙긴 것으로 전해졌다.\n",
    "\n",
    "울북부지법 형사9단독(장원정 판사)은 최근 상습절도 혐의로 기소된 60대 남성 A씨에게 징역 8개월을 선고했다. 상습장물양도 혐의로 함께 재판에 넘겨진 60대 여성 B씨 역시 징역 6개월의 실형 선고를 받았다.\n",
    "\n",
    "\n",
    "아울러 A씨는 B씨에게 매달 300만원 상당의 생활비까지 지원한 것으로 확인됐다. B씨는 A씨에게서 받은 생활비와 갈비탕을 판매해 받은 돈으로 생계를 유지해 온 것으로 알려졌다.\n",
    "\n",
    "재판에 넘겨진 A씨는 '생활비가 부족해 범행을 저질렀다'고 주장했으나 재판부는 받아들이지 않았다.\n",
    "\n",
    "장 판사는 \"A씨는 3년 이상 피해 회사의 신뢰를 배신하면서 물품을 절도해 판매했고, 피해금도 상당하다\"며 \"그 사용처 등을 고려할 때 범행 계기가 생활비 부족 때문이라는 변소도 납득하기 어렵다\"고 꼬집었다.\n",
    "\n",
    "그러면서 \"A씨가 훔친 물품의 판매 대금 중 상당액이 B씨의 주거 임대차보증금 및 기존 채무변제 등에 사용되는 등 죄질이 상당히 불량해 실형 선고가 불가피하다\"고 양형 이유를 밝혔다.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(  # Chat Completion API 호출\n",
    "    model = 'gpt-4.1-mini',\n",
    "    messages= [\n",
    "      {\"role\" : \"system\", \"content\" : \"너는 시사경제 전문가입니다. 주어진 뉴스기사의 핵심을 잘 요약/정리해주는 챗봇입니다. 사용자 입력값을 잘 읽고, 핵심내용 위주로 요약해주세요.\"},   \n",
    "      {\"role\" : \"user\", \"content\" : text} \n",
    "    ],\n",
    "    response_format= {'type' : \"text\"}, # 응답 형식\n",
    "    temperature= 0.2,                     # 모델의 랜덤성/다양성(낮으면 일관성, 높으면 창의적)\n",
    "    max_completion_tokens= 4096,        # 최대 출력 토큰\n",
    "    top_p= 1,                           # 누적확률 P까지의 후보를 샘플링(1이면 전체사용)\n",
    ")\n",
    "output = response.choices[0].message.content\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7448f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_token_len= 718\n",
      "output_token_len= 210\n"
     ]
    }
   ],
   "source": [
    "model = 'gpt-4.1-mini'\n",
    "\n",
    "try:\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "except KeyError as e:\n",
    "    print(f'warning : {model}을 찾을수 없습니다.')\n",
    "    enc = tiktoken.get_encoding('o200k_base')\n",
    "\n",
    "input_token_len = len(enc.encode(text))\n",
    "output_token_len = len(enc.encode(output))\n",
    "print(f'input_token_len= {input_token_len}')\n",
    "print(f'output_token_len= {output_token_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c39989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_cost = 0.00062825\n",
      "output_cost = 0.00147\n",
      "total_cost = 0.00209825\n"
     ]
    }
   ],
   "source": [
    "# gpt 5.2 기준 input/output price\n",
    "input_price = 0.875\n",
    "output_price = 7\n",
    "\n",
    "input_cost = (input_price / 1_000_000) * input_token_len        # 1회 호출 기준 입력 비용\n",
    "output_cost = (output_price / 1_000_000) * output_token_len     # 1회 호출 기준 출력 비용\n",
    "total_cost = input_cost + output_cost                           # 1회 호출 기준 총 비용\n",
    "\n",
    "print(\"input_cost =\", input_cost)\n",
    "print(\"output_cost =\", output_cost)\n",
    "print(\"total_cost =\", total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3833c0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monthly_total_cost =  20982.5\n"
     ]
    }
   ],
   "source": [
    "num_service_call = 10_000_000\n",
    "monthly_total_cost = total_cost * num_service_call\n",
    "print(\"monthly_total_cost = \", monthly_total_cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

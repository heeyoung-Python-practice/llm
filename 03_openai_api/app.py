import streamlit as st          # â† ì´ ì¤„ì´ ë¹ ì¡ŒìŒ
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()

api_key = os.getenv("openai_key")  # ğŸ”¥ ì´ê²ƒë„ ì¤‘ìš” (ì•„ë˜ ì„¤ëª…)
client = OpenAI(api_key=api_key)

# ì„¸ì…˜ ì´ˆê¸°í™” (ì•ˆ í•˜ë©´ ë˜ ì—ëŸ¬ë‚¨)
if "messages" not in st.session_state:
    st.session_state.messages = []

st.session_state.messages = st.session_state.messages[-10:]

@st.cache_resource
def load_model():
    return client


st.set_page_config(page_title="Chatbot", page_icon="ğŸ¤–")
st.title("ê¸°ë³¸ ì±—ë´‡ì„ streamlitìœ¼ë¡œ êµ¬í˜„í•œë‹¤.")

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ ì±—ë´‡ì´ë‹¤."}
    ]

# ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages[1:]:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# ì…ë ¥
if prompt := st.chat_input("ëŒ€í™”ë‚´ìš© ì…ë ¥"):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.write(prompt)

    response = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=st.session_state.messages
    )

    reply = response.choices[0].message.content

    st.session_state.messages.append({"role": "assistant", "content": reply})

    with st.chat_message("assistant"):
        st.write(reply)

    # íˆìŠ¤í† ë¦¬ ì œí•œ
    st.session_state.messages = st.session_state.messages[-12:]